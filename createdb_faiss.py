import pandas as pd
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
import os
from dotenv import load_dotenv
import pickle

load_dotenv()

def create_db():
    """
    Táº¡o Vector Database tá»« recipes.xlsx vá»›i FAISS
    """
    
    print("ğŸ”„ Báº¯t Ä‘áº§u táº¡o FAISS Vector Database...")
    
    # === 1. Äá»ŒC Dá»® LIá»†U ===
    data_file = "recipes_cleaned.xlsx"
    
    if not os.path.exists(data_file):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {data_file}")
        return
    
    print(f"ğŸ“– Äang Ä‘á»c file {data_file}...")
    
    # Äá»c Excel file
    df = pd.read_excel(data_file, engine='openpyxl')
    
    print(f"âœ… ÄÃ£ Ä‘á»c {len(df)} recipes")
    
    # === 2. Xá»¬ LÃ Dá»® LIá»†U ===
    docs = []
    skipped = 0
    
    for idx, row in df.iterrows():
        try:
            # Kiá»ƒm tra dá»¯ liá»‡u há»£p lá»‡
            title = str(row.get('Title', 'Unknown Recipe')).strip()
            
            # Æ¯U TIÃŠN Cleaned_Ingredients, fallback vá» Ingredients
            ingredients_cleaned = str(row.get('Cleaned_Ingredients', '')).strip()
            ingredients_raw = str(row.get('Ingredients', '')).strip()
            
            # Logic Æ°u tiÃªn
            if ingredients_cleaned and ingredients_cleaned != 'nan':
                ingredients = ingredients_cleaned
            elif ingredients_raw and ingredients_raw != 'nan':
                ingredients = ingredients_raw
            else:
                ingredients = ''
            
            instructions = str(row.get('Instructions', '')).strip()
            image_name = str(row.get('Image_Name', '')).strip()
            
            # Bá» qua náº¿u thiáº¿u thÃ´ng tin quan trá»ng
            if not title or title == 'nan':
                skipped += 1
                continue
            
            # Táº¡o ná»™i dung Ä‘á»ƒ embedding (TIáº¾NG ANH)
            content = f"""Recipe: {title}

Ingredients:
{ingredients if ingredients else 'Not specified'}

Instructions:
{instructions if instructions and instructions != 'nan' else 'Not provided'}"""
            
            formatted_image = None
            if image_name and image_name != 'nan':
                formatted_image = f"{image_name}.jpg"
            
            metadata = {
                "title": title,
                "image": formatted_image,
                "source": "recipes.xlsx",
                "row_index": idx
            }
            
            docs.append(Document(page_content=content, metadata=metadata))
            
            # Progress indicator
            if (idx + 1) % 100 == 0:
                print(f"   ÄÃ£ xá»­ lÃ½ {idx + 1}/{len(df)} recipes...")
                
        except Exception as e:
            print(f"âš ï¸ Lá»—i táº¡i dÃ²ng {idx}: {e}")
            skipped += 1
            continue
    
    print(f"âœ… ÄÃ£ táº¡o {len(docs)} documents (bá» qua {skipped} dÃ²ng lá»—i)")
    
    if len(docs) == 0:
        print("âŒ KhÃ´ng cÃ³ document nÃ o Ä‘Æ°á»£c táº¡o. Kiá»ƒm tra láº¡i file!")
        return
    
    # === 3. KHá»I Táº O EMBEDDING MODEL ===
    print("ğŸ”§ Äang táº£i embedding model (paraphrase-multilingual-MiniLM-L12-v2)...")
    print("   Model nÃ y há»— trá»£ 50+ ngÃ´n ngá»¯, tá»‘t cho cáº£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh")
    
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    print("âœ… ÄÃ£ táº£i embedding model")
    
    # === 4. Táº O FAISS VECTOR DATABASE ===
    print("ğŸ’¾ Äang táº¡o FAISS index...")
    
    faiss_dir = "./faiss_index"
    
    # XÃ³a database cÅ© náº¿u cÃ³
    if os.path.exists(faiss_dir):
        import shutil
        print(f"ğŸ—‘ï¸ XÃ³a FAISS index cÅ© táº¡i {faiss_dir}...")
        shutil.rmtree(faiss_dir)
    
    os.makedirs(faiss_dir, exist_ok=True)
    
    # Táº¡o FAISS index vá»›i batch processing
    print("   Äang embedding documents...")
    
    # FAISS xá»­ lÃ½ táº¥t cáº£ documents cÃ¹ng lÃºc
    vector_db = FAISS.from_documents(
        documents=docs,
        embedding=embeddings
    )
    
    print("âœ… ÄÃ£ táº¡o FAISS index")
    
    # === 5. LÆ¯U FAISS INDEX ===
    print(f"ğŸ’¾ Äang lÆ°u FAISS index vÃ o {faiss_dir}...")
    
    # LÆ°u FAISS index
    vector_db.save_local(faiss_dir)
    
    print(f"âœ… ÄÃ£ lÆ°u FAISS index táº¡i {faiss_dir}")
    print(f"ğŸ“Š Tá»•ng sá»‘ documents: {len(docs)}")
    
    # === 6. KIá»‚M TRA DATABASE ===
    print("\nğŸ§ª Kiá»ƒm tra FAISS index...")
    
    # Load láº¡i Ä‘á»ƒ test
    test_db = FAISS.load_local(
        faiss_dir, 
        embeddings,
        allow_dangerous_deserialization=True
    )
    
    # Test search
    test_queries = ["pizza", "chocolate cake", "pasta"]
    
    for query in test_queries:
        results = test_db.similarity_search(query, k=1)
        if results:
            print(f"   âœ“ Query '{query}' â†’ Found: {results[0].metadata['title']}")
        else:
            print(f"   âœ— Query '{query}' â†’ No results")
    
    print("\nğŸ‰ HoÃ n táº¥t! FAISS Database Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng.")
    print(f"ğŸ“ Files created:")
    print(f"   - {faiss_dir}/index.faiss (vector index)")
    print(f"   - {faiss_dir}/index.pkl (metadata)")

if __name__ == "__main__":
    create_db()